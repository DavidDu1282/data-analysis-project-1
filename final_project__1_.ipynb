{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt,pi\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import date\n",
    "import string, re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#set up pyspark\n",
    "from pyspark.sql import SparkSession, functions, types\n",
    "spark = SparkSession.builder.appName('Word Count').getOrCreate()\n",
    "spark.sparkContext.setLogLevel('WARN')\n",
    "\n",
    "assert sys.version_info >= (3, 5) # make sure we have Python 3.5+\n",
    "assert spark.version >= '2.3' # make sure we have Spark 2.3+\n",
    "\n",
    "amenities_schema = types.StructType([\n",
    "    types.StructField('lat', types.DoubleType()),\n",
    "    types.StructField('lon', types.DoubleType()),\n",
    "    types.StructField('timestamp', types.TimestampType() ),\n",
    "    types.StructField('amenity', types.StringType()),\n",
    "    types.StructField('name', types.StringType() ),\n",
    "    types.StructField('tags', types.MapType(types.StringType(),types.StringType())),\n",
    "])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df = spark.read.json('amenities-vancouver.json.gz', schema = amenities_schema)\n",
    "df = df.filter(df['name'].isNotNull()).cache() #filter non name and cache dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "special_words_list = ['Agritourism', 'Gaming', 'Sports', 'Recreation', 'Motion Picture']#, 'Arts', 'Botanical Gardens', 'Zoos', 'Heritage', 'Park', 'Sculpture', 'Aquarium', 'Mountain']\n",
    "\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "\n",
    "for word in special_words_list:\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "\n",
    "def remove_(words):\n",
    "    new_words = words.replace(\"_\", \" \")\n",
    "    return new_words\n",
    "res = list(map(remove_, synonyms))\n",
    "\n",
    "print(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['gambling', 'gaming', 'play', 'bet on', 'back', 'gage', 'stake', 'game', 'punt', 'sport', 'athletics', 'sport', 'sport', 'summercater', 'sport', 'sport', 'sportsman', 'sportswoman', 'mutant', 'mutation', 'variation', 'sport', 'fun', 'play', 'sport', 'sport', 'feature', 'boast', 'frolic', 'lark', 'rollick', 'skylark', 'disport', 'sport', 'cavort', 'gambol', 'frisk', 'romp', 'run around', 'lark about', 'diversion', 'recreation', 'refreshment', 'recreation']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "wordbreak = r'[%s\\s]+' % (re.escape(string.punctuation),)\n",
    "\n",
    "split_names = df.select(\n",
    "    functions.explode(functions.split(functions.lower(df['name']),pattern = wordbreak, limit = -1 )).alias('split_name'),\n",
    "    df['lat'],         \n",
    "    df['lon'],          \n",
    "    df['timestamp'],\n",
    "    df['amenity']\n",
    ").cache() #splits each tag into their own row\n",
    "\n",
    "\n",
    "list_positive_names = res\n",
    "def is_pos_name(name):\n",
    "    return name in list_positive_names\n",
    "are_positive_names = functions.udf(is_pos_name, returnType=types.BooleanType())\n",
    "pos_names_locations = split_names.filter(are_positive_names(split_names['split_name']))\n",
    "\n",
    "\n",
    "#attempting to match close enough words, currently unsuccessful\n",
    "# import difflib\n",
    "\n",
    "# def match_misspelled_words(df_keywords,  split_names_list):\n",
    "#     matching_ratings = ratings[ratings['title'].isin(difflib.get_close_matches(df_keywords['key_words'], split_names_list['split_name']))]\n",
    "#     #print(matching_ratings)\n",
    "#     return round(matching_ratings['rating'].mean(),2)\n",
    "\n",
    "\n",
    "# split_names_list = split_names.select('split_name').toPandas()\n",
    "# pos_names_locations = split_names.filter(split_names['split_name'].isin())\n",
    "# df_keywords = pd.DataFrame(res, columns = ['key_words'])\n",
    "# df_keywords.head(10)\n",
    "# difflib.get_close_matches(df_keywords['key_words'],split_names_list['split_name'])\n",
    "\n",
    "\n",
    "# movie_list['rating'] = movie_list.apply(match_misspelled_words, axis = 1, raw =  False, result_type = 'reduce',  ratings = ratings_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pos_names_locations.count()\n",
    "\n",
    "pos_names_locations_full = df.join(pos_names_locations, ['lat', 'lon', 'timestamp', 'amenity'])\n",
    "pos_names_locations_full.coalesce(1).write.json('locations_pos_names', mode='overwrite')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "##counts_name = df.groupby('name').agg(functions.count('lat').alias('count')) \n",
    "##counts_name = counts_name.filter(counts_name['count']<2) #filters non-unique names\n",
    "\n",
    "##df = df.join(other = counts_name, on='name') #joins back\n",
    "\n",
    "tags = df.select(\n",
    "    df['name'],\n",
    "    df['lat'],         \n",
    "    df['lon'],          \n",
    "    df['timestamp'],\n",
    "    df['amenity'],\n",
    "    #df['count'],\n",
    "    functions.explode(df['tags'])\n",
    ").cache() #splits each tag into their own row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "keys_and_values = tags.groupBy(['key', 'value']).agg(functions.count('name').alias('count'))\n",
    "keys_and_values.filter(keys_and_values['count'] > 5).coalesce(1).write.csv('keys_and_values_counts', mode='overwrite')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "list_positive_tags = res\n",
    "def is_pos_tag(tag):\n",
    "    return tag in list_positive_tags\n",
    "are_positive_tags = functions.udf(is_pos_tag, returnType=types.BooleanType())\n",
    "pos_key_locations = tags.filter(are_positive_tags(tags['key']))\n",
    "pos_value_locations = tags.filter(are_positive_tags(tags['value']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df_keywords['key_words']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        gambling\n",
       "1          gaming\n",
       "2            play\n",
       "3          bet on\n",
       "4            back\n",
       "5            gage\n",
       "6           stake\n",
       "7            game\n",
       "8            punt\n",
       "9           sport\n",
       "10      athletics\n",
       "11          sport\n",
       "12          sport\n",
       "13    summercater\n",
       "14          sport\n",
       "15          sport\n",
       "16      sportsman\n",
       "17    sportswoman\n",
       "18         mutant\n",
       "19       mutation\n",
       "20      variation\n",
       "21          sport\n",
       "22            fun\n",
       "23           play\n",
       "24          sport\n",
       "25          sport\n",
       "26        feature\n",
       "27          boast\n",
       "28         frolic\n",
       "29           lark\n",
       "30        rollick\n",
       "31        skylark\n",
       "32        disport\n",
       "33          sport\n",
       "34         cavort\n",
       "35         gambol\n",
       "36          frisk\n",
       "37           romp\n",
       "38     run around\n",
       "39     lark about\n",
       "40      diversion\n",
       "41     recreation\n",
       "42    refreshment\n",
       "43     recreation\n",
       "Name: key_words, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "pos_key_locations.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----------+------------+-------------------+-----------------+-----+---------+\n",
      "|                name|       lat|         lon|          timestamp|          amenity|  key|    value|\n",
      "+--------------------+----------+------------+-------------------+-----------------+-----+---------+\n",
      "|Aikido Yoshinkai ...|49.2237917|-122.9418357|2019-09-02 22:08:26|             dojo|sport|   aikido|\n",
      "|I Love Martial Ar...| 49.057546|-122.2738986|2018-06-20 15:11:24|             dojo|sport|   karate|\n",
      "|Mamba Martial Art...|49.0468605|-122.3483787|2018-06-20 15:12:01|             dojo|sport|    multi|\n",
      "|Yoga and Meditati...|49.0463884|-122.3485056|2016-06-13 22:36:29|meditation_centre|sport|     yoga|\n",
      "|Jong Kim Martial ...|49.1852717| -122.798376|2019-03-07 14:56:23|             dojo|sport|taekwondo|\n",
      "|             Re.pose|49.0497557|-122.2907591|2019-03-16 01:57:47|             dojo|sport|     yoga|\n",
      "+--------------------+----------+------------+-------------------+-----------------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "list_positive_amenities = ['public_building', 'theatre', 'food_court', 'community_centre', 'cinema', 'casino', 'park' , 'university']\n",
    "def is_pos_amenity(amenity):\n",
    "    return amenity in list_positive_amenities\n",
    "are_positive_amenities = functions.udf(is_pos_amenity, returnType=types.BooleanType())\n",
    "pos_amenities_locations = df.filter(are_positive_amenities(df['amenity']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "amenities = df.groupBy('amenity').agg(functions.count('name').alias('count'))\n",
    "amenities.coalesce(1).write.csv('amenties_counts', mode='overwrite') #safe to do as this only contains unique types of amenities"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "pos_amenities_locations.count()\n",
    "pos_amenities_locations.coalesce(1).write.json('locations_pos_amenities', mode='overwrite')#safe to do as this only contains the tourist attractions in Vancouver (125 rows)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#finds all with wikidata entry, rename 'value' to 'wikidata'\n",
    "tag_wikidata = tags.filter(tags['key'] == \"brand:wikidata\")\n",
    "tag_wikidata = tag_wikidata.select(\n",
    "    tag_wikidata['name'],\n",
    "    tag_wikidata['lat'],         \n",
    "    tag_wikidata['lon'],          \n",
    "    tag_wikidata['timestamp'],\n",
    "    tag_wikidata['amenity'],\n",
    "    tag_wikidata['value'].alias('wikidata')\n",
    " ).cache()\n",
    "\n",
    "#finds all with wikipedia entry, rename 'value' to 'wikipedia'\n",
    "tag_wikipedia = tags.filter(tags['key'] == \"wikipedia\")\n",
    "tag_wikipedia = tag_wikipedia.select(\n",
    "    tag_wikipedia['name'],\n",
    "    tag_wikipedia['lat'],         \n",
    "    tag_wikipedia['lon'],          \n",
    "    tag_wikipedia['timestamp'],\n",
    "    tag_wikipedia['amenity'],\n",
    "    tag_wikipedia['value'].alias('wikipedia')\n",
    " ).cache()\n",
    "\n",
    "place_tourism = tags.filter(tags['key'] == \"tourism\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "counts_wikipedia = tag_wikipedia.groupBy(['wikipedia']).agg(functions.count('name').alias('count')) \n",
    "counts_wikipedia = counts_wikipedia.filter(counts_wikipedia['count']<2) #filters non-unique wikis\n",
    "place_wikipedia = tag_wikipedia.join(counts_wikipedia, on = ['wikipedia'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "counts_wikidata = tag_wikidata.groupBy(['wikidata']).agg(functions.count('name').alias('count')) \n",
    "counts_wikidata = counts_wikidata.filter(counts_wikidata['count']<2) #filters non-unique wikis\n",
    "place_wikidata = tag_wikidata.join(counts_wikidata, on = ['wikidata'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#place_wikidata.count()\n",
    "#place_wikipedia.count()\n",
    "#place_tourism.count()\n",
    "#place_tourism.show()\n",
    "#place_wikidata.show()\n",
    "#place_wikipedia.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#abandoned pandas code\n",
    "data = pd.read_json('amenities-vancouver.json.gz', lines=True).dropna(subset=['name']) #drop rows where there is no name\n",
    "\n",
    "#find the counts of names\n",
    "counts = data.groupby(by = ['name']).aggregate('count')\n",
    "#remove non-unique names\n",
    "counts = counts[counts['lat'] < 2]\n",
    "counts['count'] = counts['lat']\n",
    "counts = counts.drop(labels= ['lat', 'lon',\t'timestamp',\t'amenity',\t'tags'], axis = 1)\n",
    "\n",
    "#join back for only columns with an unique name\n",
    "data = data.join(counts, on=['name'], how = 'inner')\n",
    "\n",
    "data['tags'].iloc[10]['brand:wikidata']\n",
    "'brand:wikidata' in data['tags'].iloc[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}